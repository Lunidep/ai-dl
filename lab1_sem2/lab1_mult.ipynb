{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73odbN7OzpXS"
      },
      "source": [
        "# Лабораторная работа 1\n",
        "\n",
        "Попов Илья, 406"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание\n",
        "1. Подробно изучить [туториал](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) и написать комментарий к каждой строчке кода\n",
        "2. Выбрать наборы данных и обосновать его выбор (реальная практическая задача)\n",
        "3. Выбрать метрики качества и обосновать их выбор\n",
        "4. Создание бейзлайна и оценка качества\n",
        "5. Улучшение бейзлайна\n",
        "  * Сформулировать гипотезы (подбор аугментаций и других гиперпараметров, подбор архитектуры нейронной сети)\n",
        "  * Проверить гипотезы\n",
        "  * Сравнить результаты моделей в сравнении с результатами из пункта 4\n",
        "  * Сделать выводы\n",
        "6. Реализация нейросетевой архитектуры\n",
        "  * Самостоятельно реализовать выбранную нейронную сеть\n",
        "  * Сравнить результаты моделей в сравнении с результатами из пункта 5\n",
        "  * Сделать выводы"
      ],
      "metadata": {
        "id": "e7of9qNsGKMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Изучение туториала\n",
        "\n",
        "После изучения материала стало понятно, что основная цель трансферного обучения заключается в передаче знаний, полученных на одной задаче, на другую. Это достигается путем замораживания первых N слоев нейронной сети, ответственных за извлечение базовых признаков, и обучения новых слоев для решения конкретной задачи, например, классификации.\n",
        "\n",
        "Разберем, что значат основные шаги в этом плейбуке для колаба:\n",
        "\n",
        "1. Аугментация данных. Здесь мы применяем несколько методов для увеличения разнообразия обучающего набора: случайное обрезание изображения до размера 224x224 пикселей и случайное отражение по горизонтали. Это помогает модели лучше обучиться на различных вариантах изображений.\n",
        "\n",
        "2. Нормализация данных. Мы меняем размер изображения до 256x256 пикселей, а затем вырезаем центральную область размером 224x224 пикселей. Это стандартная практика для подготовки данных перед подачей их на вход нейронной сети.\n",
        "\n",
        "3. Загрузка предварительно обученной модели ConvNet. Мы используем модель ResNet-18, обученную на наборе данных IMAGENET1K_V1. Это позволяет нам использовать заранее обученные веса, захватывающие общие признаки изображений, которые могут быть адаптированы к нашей конкретной задаче.\n",
        "\n",
        "4. Отключение обучения для некоторых слоев. Это достигается установкой параметра requires_grad в False для этих слоев. Этот шаг полезен, когда мы хотим использовать предобученные веса и избежать их изменения.\n",
        "\n",
        "5. Применение регуляризации весов с помощью lr_scheduler.StepLR. Этот метод позволяет регулировать скорость обучения в зависимости от эпох обучения. Уменьшение скорости обучения через каждые 7 эпох с коэффициентом 0.1 помогает предотвратить переобучение модели."
      ],
      "metadata": {
        "id": "EQNL5JzZBOKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Выбор набора данных\n",
        "Выбрана задача классификации изображений муравьев и пчел с использованием [датасета](https://download.pytorch.org/tutorial/hymenoptera_data.zip) с Kaggle. Она подходит для задачи классификации изображений с использованием transfer learning."
      ],
      "metadata": {
        "id": "dKDJDUfmBXJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Выбор метрики качества\n",
        "\n",
        "При выборе Accuracy я сравнивал ее с другими метриками, такими как Precision, Recall и F1-score. Хотя каждая из этих метрик имеет свои преимущества, мне показалось, что Accuracy лучше всего подходит для моей конкретной задачи классификации изображений муравьев и пчел. В отличие от Precision, которая фокусируется на точности предсказаний положительного класса, и Recall, которая измеряет способность модели обнаруживать все положительные примеры, Accuracy предоставляет более общую оценку производительности модели, что было важно для меня в данной ситуации. Кроме того, в отличие от F1-score, который учитывает как Precision, так и Recall, Accuracy была более простой и интуитивно понятной для интерпретации, что соответствовало моим целям в выборе метрики."
      ],
      "metadata": {
        "id": "47oWLi96DQVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Создание бейзлайна\n",
        "\n",
        "Выбор использовать ResNet-18 с весами IMAGENET1K_V1 в качестве основной модели был сделан после тщательного анализа доступных архитектур и ресурсов. ResNet-18 представляет собой компактную и эффективную архитектуру, позволяющую достичь хороших результатов в задачах классификации изображений, что делает ее привлекательным выбором для моего проекта.\n",
        "\n",
        "Использование предобученных весов IMAGENET1K_V1 обусловлено желанием скорее запустить процесс обучения и сэкономить время, чем начинать с нуля. Предобученные веса содержат информацию о широком спектре изображений, что может помочь модели лучше обобщать и адаптироваться к новым данным.\n",
        "\n",
        "Кроме того, ResNet-18 с весами IMAGENET1K_V1 предоставляет отличную отправную точку для дальнейших экспериментов и улучшений. После оценки базовой модели я планирую исследовать различные методы дообучения и адаптации модели к моей конкретной задаче, такие как fine-tuning и аугментация данных."
      ],
      "metadata": {
        "id": "uDPqzLfajf-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download dataset"
      ],
      "metadata": {
        "id": "ca924f-dHrG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir dataset && wget -P dataset/ https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "! unzip -q dataset/hymenoptera_data.zip -d dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XLOchG-DzRE",
        "outputId": "709599e3-5bed-40ef-f6ce-96778b8d85fe",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-11 17:35:39--  https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 18.239.225.41, 18.239.225.75, 18.239.225.61, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|18.239.225.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47286322 (45M) [application/zip]\n",
            "Saving to: ‘dataset/hymenoptera_data.zip’\n",
            "\n",
            "hymenoptera_data.zi 100%[===================>]  45.10M  64.3MB/s    in 0.7s    \n",
            "\n",
            "2024-05-11 17:35:40 (64.3 MB/s) - ‘dataset/hymenoptera_data.zip’ saved [47286322/47286322]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  #### Useful imports\n"
      ],
      "metadata": {
        "id": "CkoRtDbwKLXw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiD3IYsdzpXT",
        "outputId": "85c5893e-1426-4d3f-864c-56f1698919c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.ExitStack at 0x7ffba6f9e170>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from tqdm.auto import tqdm, trange\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Process dataset\n",
        "\n",
        "Тут происходят преобразования изображений, такие как обрезка до определенного размера и преобразование в формат тензора, затем создаются объекты для загрузки данных, учитывая пакетную обработку, перемешивание и количество рабочих процессов для ускорения. Размеры наборов данных и список классов изображений также определяются здесь."
      ],
      "metadata": {
        "id": "k8viHi0jLrS5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bOsMvlZ9zpXU",
        "outputId": "ed30a11c-cf83-4501-f445-54085955804a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'dataset/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare network\n",
        "Здесь происходит инициализация модели ResNet-18 с предварительными весами изображений ImageNet. Последний полносвязанный слой модели адаптируется под количество классов в наборе данных. Модель перемещается на выбранное устройство для обучения. Для расчета потерь используется кросс-энтропия, а для обновления весов модели используется оптимизатор Stochastic Gradient Descent (SGD). Устанавливается уменьшение скорости обучения с помощью StepLR для динамической адаптации скорости обучения."
      ],
      "metadata": {
        "id": "oYEZnv7FOK6A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7iHDzXOzpXW",
        "outputId": "8e6a9bb6-6dfd-41ae-fa27-0a0cbeca22de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 105MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNfVqsUAzpXV"
      },
      "source": [
        "#### Fit model\n",
        "Внутри функции идет цикл по эпохам, в каждой эпохе обучение и валидация модели."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tempfile import TemporaryDirectory\n",
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        pbar = tqdm(total=num_epochs, desc='Training Progress', position=0)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()\n",
        "                else:\n",
        "                    model.eval()\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                pbar.set_description(f'Epoch {epoch}/{num_epochs - 1} {phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ],
      "metadata": {
        "id": "ks3tu9bhOjej"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23482b0d-52db-46e0-b6a3-c9d432dbd819",
        "id": "BsfU3m722m_z"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/24 val Loss: 0.1863 Acc: 0.9216: 100%|█| 25/25 [00:25<00:00,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete in 0m 25s\n",
            "Best val Acc: 0.934641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_ft= train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Вывод\n",
        "\n",
        "По результатам двух проходов обучения с постоянным числом эпох (25) и теми же параметрами, модель достигла достаточно высокой точности на валидационном наборе данных.\n",
        "Обученная сеть показала отличные результаты - 93% на выборке валидации."
      ],
      "metadata": {
        "id": "GTk7Nn9ND2f8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Улучшение бейзлайна\n",
        "\n",
        "Для улучшения модели планируется использовать аугментацию данных и заморозить все слои, кроме последнего. Это достигается путем установки параметра requires_grad в False для всех параметров модели, что предотвратит обновление их значений во время обратного распространения ошибки (backward()). Такой подход поможет сосредоточиться на обучении только последнего слоя, что может привести к улучшению обобщающей способности модели и предотвращению переобучения.\n",
        "\n"
      ],
      "metadata": {
        "id": "h7uyXExzD5TY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Process dataset"
      ],
      "metadata": {
        "id": "sTpeLVBJwXgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'dataset/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "1WbcoeSSTQn_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6_wJJ3HAzpXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f792de-c7d9-4f0a-e1bf-4f4c1bab781e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:01<00:00, 44.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyZrIq71zpXX",
        "outputId": "cad4b458-2120-4ad9-ef46-d677c8189876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Progress:   0%|          | 0/25 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Epoch 24/24 val Loss: 0.1855 Acc: 0.9412: 100%|██████████| 25/25 [18:32<00:00, 44.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete in 18m 33s\n",
            "Best val Acc: 0.954248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Вывод\n",
        "\n",
        "После внесения улучшений в модель, включая аугментацию данных и замораживание параметров слоев, мы достигли заметного увеличения точности на валидационном наборе данных с 93.4% до 95.42%. Это демонстрирует эффективность выбранных улучшений и подтверждает их значительное влияние на результаты модели."
      ],
      "metadata": {
        "id": "X1Cr3a3zD7cG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Реализация архитектуры"
      ],
      "metadata": {
        "id": "cSDwMJQ9EA00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "В качестве архитектуры выбран ResNet с использованием блоков Residual Block. Каждый Residual Block состоит из двух сверточных слоев с функцией активации ReLU и слоев Batch Normalization.\n",
        "\n",
        "Класс ResNet определяет архитектуру сети, включая сверточные слои, слои пулинга, а также последовательность блоков Residual Block. Здесь используются четыре последовательных слоя блоков Residual Block с различным количеством фильтров.\n",
        "\n",
        "Функция _make_layer создает последовательность блоков Residual Block для каждого слоя ResNet, принимая на вход количество фильтров и количество блоков в слое. Если изменяется размерность входных данных или количество фильтров, применяется слой с 1x1 сверткой для подстройки размерности.\n",
        "\n",
        "В методе forward определяется последовательное выполнение сверточных слоев, пулинга, блоков Residual Block и классификационного слоя. Размерность выхода усредняется по пространственным размерам с помощью слоя AvgPool2d и подается на классификационный слой для получения предсказаний."
      ],
      "metadata": {
        "id": "pjxBsW7hzz8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Почему выбор пал на ResNet\n",
        "\n",
        "Выбор модели ResNet для решения задачи обычно обусловлен ее хорошей производительностью в различных компьютерных зрении задачах. Вот несколько причин, по которым ResNet может быть выбрана:\n",
        "\n",
        "Глубина сети: ResNet имеет глубокую архитектуру, что позволяет ей изучать сложные иерархии признаков на изображениях. Это особенно полезно для задач, где необходимо извлечь высокоуровневые признаки, такие как семантическая сегментация или классификация изображений.\n",
        "\n",
        "Skip connections: ResNet включает в себя \"skip connections\" или \"residual connections\", которые позволяют градиентам более эффективно распространяться по сети во время обратного распространения ошибки. Это помогает в борьбе с проблемой затухания градиентов и позволяет обучать глубокие сети более успешно.\n",
        "\n",
        "Производительность и эффективность: ResNet обеспечивает хорошую производительность на различных наборах данных и демонстрирует небольшое количество параметров по сравнению с некоторыми другими архитектурами. Это делает его привлекательным выбором для решения различных задач компьютерного зрения.\n",
        "\n",
        "Предварительно обученные модели: ResNet представлен в предварительно обученной форме на больших наборах данных, таких как ImageNet. Это позволяет использовать предварительно обученные веса для переноса обучения, что ускоряет процесс обучения и улучшает общую производительность модели."
      ],
      "metadata": {
        "id": "v_-8Shq7d_Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels),\n",
        "                        nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(\n",
        "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels))\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "bjUBFRBZ_q9m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU())\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
        "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
        "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
        "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1Ug07V0N_viQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Лосс-функция определяется как CrossEntropyLoss(), которая часто используется для задач классификации.\n",
        "\n",
        "Оптимизатор настроен как стохастический градиентный спуск (SGD) с параметрами скорости обучения (lr=0.001) и момента (momentum=0.9). Он используется для обновления параметров модели в процессе обучения.\n",
        "\n",
        "Для управления скоростью обучения используется шедулер StepLR, который уменьшает скорость обучения на заданный коэффициент gamma=0.1 каждые step_size=7 эпох."
      ],
      "metadata": {
        "id": "hIbFgZ7LaV3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet(ResidualBlock, [3, 4, 6, 3]).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "eAq8Av3r_1NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = train_model(model_conv, criterion, optimizer, scheduler, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f80e258-bf9d-4fba-8146-59fe0b4784e5",
        "id": "F_Qrg7s015A4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/99 val Loss: 0.7176 Acc: 0.6013: 100%|█| 100/100 [01:32<00:00,  1.09it/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete in 1m 32s\n",
            "Best val Acc: 0.601307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Вывод\n",
        "\n",
        "После введения архитектуры ResNet и обучения модели в течение 100 эпох, мы получили точность на валидационном наборе данных около 60.13%. Это может свидетельствовать о том, что модель не смогла достаточно хорошо обобщить обучающие данные и показать хорошие результаты на новых данных.\n",
        "\n"
      ],
      "metadata": {
        "id": "zzLPHV87CNuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Общий вывод\n",
        "В небольших наборах данных обучать модель с нуля нецелесообразно из-за вероятности получить низкое качество результатов. Трансферное обучение представляет собой более эффективный подход, поскольку предварительно обученная модель уже обладает опытом работы с изображениями, и дообучение ее для конкретной задачи в таком случае является более оптимальным."
      ],
      "metadata": {
        "id": "x2copZM83nMU"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e7of9qNsGKMR"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}